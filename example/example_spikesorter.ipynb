{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is necessary for having figures directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from tridesclous import SpikeSorter, CatalogueWindow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download Locust dataset from zenedo.\n",
    "We take 3 trials in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "name = 'locust20010201.hdf5'\n",
    "distantfile = 'https://zenodo.org/record/21589/files/'+name\n",
    "localfile = name\n",
    "if not os.path.exists(localfile):\n",
    "    urlretrieve(distantfile, localfile)\n",
    "hdf = h5py.File(localfile,'r')\n",
    "\n",
    "# read 3 trials (=3 segments)\n",
    "ch_names = ['ch09','ch11','ch13','ch16']\n",
    "trial_names = ['trial_01', 'trial_02', 'trial_03']\n",
    "sigs_by_trials = []\n",
    "for trial_name in trial_names:\n",
    "    sigs = np.array([hdf['Continuous_1'][trial_name][name][...] for name in ch_names]).transpose()\n",
    "    sigs = (sigs.astype('float32') - 2**15.) / 2**15\n",
    "    sigs_by_trials.append(sigs)\n",
    "\n",
    "sampling_rate = 15000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpikeSorter: insert several segments\n",
    "\n",
    "Create our data manager and append some data into it.\n",
    "Note that our data is already filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikesorter = SpikeSorter(dirname = 'Dataset several segment')\n",
    "\n",
    "for seg_num in range(3):\n",
    "    sigs = sigs_by_trials[seg_num]\n",
    "    spikesorter.dataio.append_signals_from_numpy(sigs, seg_num = seg_num,\n",
    "                t_start = 0.+5*seg_num, sampling_rate =  sampling_rate, \n",
    "                signal_type = 'unfiltered', channels = ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(spikesorter.summary(level=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikesorter.apply_filter(highpass_freq = 0., box_smooth = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Detect peak an dextract waveform in one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikesorter.detect_peaks_extract_waveforms(seg_nums = 'all',  threshold=-4, \n",
    "                                    peak_sign = '-', n_span = 2, n_left=-30, n_right=50)\n",
    "print(spikesorter.summary(level=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# project and find cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikesorter.project(method = 'pca', n_components = 5)\n",
    "spikesorter.find_clusters(7)\n",
    "spikesorter.refresh_colors(reset=True, palette = 'husl')\n",
    "print(spikesorter.summary(level=1))\n",
    "print(spikesorter.cluster_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open interactive windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%gui qt4\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = CatalogueWindow(spikesorter)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spikesorter.appy_peeler(seg_nums = 'all', levels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spiketrains = spikesorter.dataio.get_spiketrains(seg_num=0)\n",
    "spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spiketrains = spikesorter.dataio.get_spiketrains(seg_num=1)\n",
    "spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spiketrains = spikesorter.dataio.get_spiketrains(seg_num=2)\n",
    "spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
