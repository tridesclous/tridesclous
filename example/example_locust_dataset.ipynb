{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *tridesclous* example with locust dataset\n",
    "\n",
    "Here a detail notebook that detail the locust dataset recodring by Christophe Pouzat.\n",
    "\n",
    "This dataset is our classic.\n",
    "It has be analyse yet by several tools in R, Python or C:\n",
    "  * https://github.com/christophe-pouzat/PouzatDetorakisEuroScipy2014\n",
    "  * https://github.com/christophe-pouzat/SortingABigDataSetWithPython\n",
    "  * http://xtof.perso.math.cnrs.fr/locust.html\n",
    "\n",
    "So we can compare the result.\n",
    "\n",
    "The original datasets is here https://zenodo.org/record/21589\n",
    "\n",
    "But we will work on a very small subset on github https://github.com/tridesclous/tridesclous_datasets/tree/master/locust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In *tridesclous*, the spike sorting is done in several step:\n",
    "  * Define the datasource and working path. (class DataIO)\n",
    "  * Construct a *catalogue* (class CatalogueConstructor) on a short chunk of data (for instance 60s)\n",
    "    with several sub step :\n",
    "    * signal pre-processing:\n",
    "      * high pass filter (optional)\n",
    "      * removal of common reference (optional)\n",
    "      * noise estimation (median/mad) on a small chunk\n",
    "      * normalisation = robust z-score\n",
    "    * peak detection\n",
    "    * extract some waveform. Unecessary and impossible to extract them all.\n",
    "    * find rational limit of waveforms (n_left/n_right)\n",
    "    * project theses waveforms in smaller dimention (pca, ...)\n",
    "    * find cluster\n",
    "    * clean with GUI (class CatalogueWindow)\n",
    "    * save centroids (median+mad + first and second derivative)\n",
    "  * Apply the *Peeler* (class Peeler) on the long term signals. With several sub steps:\n",
    "     * same signal preprocessing than before\n",
    "     * find peaks\n",
    "     * find the best cluster in catalogue for each peak\n",
    "     * find the intersample jitter\n",
    "     * remove the oversampled waveforms from the signals until there are not peaks in the signals.\n",
    "     * check with GUI (class PeelerWindow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/Documents/projet/tridesclous/tridesclous/__init__.py:19: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-15909cd08ded>\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2131, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-107>\", line 2, in matplotlib\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/magic.py\", line 187, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 99, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/home/samuel/.virtualenvs/py36/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Qt5Agg')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tridesclous as tdc\n",
    "\n",
    "from tridesclous import DataIO, CatalogueConstructor, Peeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a small dataset\n",
    "\n",
    "trideclous provide some datasets than can be downloaded with **download_dataset**.\n",
    "\n",
    "Note this dataset contains 2 trials in 2 different files. (the original contains more!)\n",
    "\n",
    "Each file is considers as a *segment*. *tridesclous* automatically deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/samuel/Documents/projet/tridesclous/example/locust/locust_trial_01.raw', '/home/samuel/Documents/projet/tridesclous/example/locust/locust_trial_02.raw']\n",
      "{'dtype': 'int16', 'sample_rate': 15000.0, 'total_channel': 4}\n"
     ]
    }
   ],
   "source": [
    "#download dataset\n",
    "localdir, filenames, params = tdc.download_dataset(name='locust')\n",
    "print(filenames)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataIO = define datasource and working dir\n",
    "\n",
    "\n",
    "Theses 2 files are in **RawData** format this means binary format with interleaved channels.\n",
    "\n",
    "Our dataset contains 2 segment of 28.8 second each, 4 channels. The sample rate is 15kHz.\n",
    "\n",
    "Note that there is only one channel_group here (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIO <id: 139632851524968> \n",
      "  workdir: tridesclous_locust\n",
      "  sample_rate: 15000.0\n",
      "  total_channel: 4\n",
      "  channel_groups: 0 [ch0 ch1 ch2 ch3]\n",
      "  nb_segment: 2\n",
      "  length: 431548 431548\n",
      "  durations: 28.8 28.8 s.\n"
     ]
    }
   ],
   "source": [
    "#create a DataIO\n",
    "import os, shutil\n",
    "dirname = 'tridesclous_locust'\n",
    "if os.path.exists(dirname):\n",
    "    #remove is already exists\n",
    "    shutil.rmtree(dirname)    \n",
    "dataio = DataIO(dirname=dirname)\n",
    "\n",
    "# feed DataIO\n",
    "dataio.set_data_source(type='RawData', filenames=filenames, **params)\n",
    "print(dataio)\n",
    "\n",
    "#no need to setup the prb with dataio.set_probe_file() or dataio.download_probe()\n",
    "#because it is a tetrode\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatalogueConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  Signal pre-processing not done yet\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor = CatalogueConstructor(dataio=dataio)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters for the pre-processing step.\n",
    "\n",
    "For a complet description of each params see main documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogueconstructor.set_preprocessor_params(chunksize=1024,\n",
    "            common_ref_removal=False,\n",
    "            highpass_freq=300.,\n",
    "            lowpass_freq=5000.,                                             \n",
    "            lostfront_chunksize=64,\n",
    "            peak_sign='-',\n",
    "            relative_threshold=6.5,\n",
    "            peak_span=0.0001,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the median and mad of noiseon a small chunk of filtered signals.\n",
    "This compute medians and mad of each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2877347 0.8443531 1.6870663 0.5088713]\n",
      "[51.053234 46.69039  57.44741  44.837955]\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.estimate_signals_noise(seg_num=0, duration=15.)\n",
    "print(catalogueconstructor.signals_medians)\n",
    "print(catalogueconstructor.signals_mads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the main loop: signal preprocessing + peak detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_signalprocessor 0.9844878860003519 s\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  cluster_labels [-11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.run_signalprocessor(duration=60.)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print('run_signalprocessor', t2-t1, 's')\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract some waveforms\n",
    "\n",
    "Take some waveforms in the signals *n_left/n_right* must be choosen arbitrary but lon enought.\n",
    "Better limits will be set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_all_centroid 0.02803275299993402\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  some_waveforms.shape: (1323, 65, 4)\n",
      "  cluster_labels [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.extract_some_waveforms(n_left=-25, n_right=40, mode='rand', nb_max=10000, align_waveform=True)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean waveforms\n",
    "\n",
    "Whis try to detect bad waveforms to not include them in features aand clustering.\n",
    "Strange waveforms are tag with -9 (alien)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_all_centroid 0.027273296000203118\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  some_waveforms.shape: (1323, 65, 4)\n",
      "  cluster_labels [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catalogueconstructor.clean_waveforms(alien_value_threshold=100.)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find good limits for waveforms and re-extract\n",
    "\n",
    "To avoid useless portion of signal on the sides of peaks we take smaller sweep.\n",
    "This technics is based on the MAD. We take only central zone where the MAD is above the noise.\n",
    "Noise is 1. In practice we take a bit more 1.1\n",
    "\n",
    "Here the methods give a \"good limts\" of n_left -10 n_right 15.\n",
    "\n",
    "So the shape of waveforms become smaller.\n",
    "\n",
    "Note that this technic work well on tetrode or small channel number but for large array it is as good as manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_all_centroid 0.01800733700110868\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  some_waveforms.shape: (1323, 24, 4)\n",
      "  cluster_labels [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_left, n_right = catalogueconstructor.find_good_limits(mad_threshold = 1.1,)\n",
    "print(catalogueconstructor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project to smaller space\n",
    "\n",
    "To reduce dimension of the waveforms (1323, 24, 4) we chosse global_pac method which is appropriate for tetrode.\n",
    "It consists of flatenning some_waveforms.shape (1323, 24, 4) to (1323, 24x4) and then apply a standard PCA on it with sklearn.\n",
    "\n",
    "Let's keep 5 component of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project 0.07931107900003553\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  some_waveforms.shape: (1323, 24, 4)\n",
      "  some_features.shape: (1323, 5)\n",
      "  cluster_labels [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.extract_some_features(method='global_pca', n_components=5)\n",
    "t2 = time.perf_counter()\n",
    "print('project', t2-t1)\n",
    "print(catalogueconstructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find clusters\n",
    "\n",
    "There are many option to cluster this features. here a simple one the well known kmeans method.\n",
    "\n",
    "Unfortunatly we need to choose the number of cluster. Too bad... Let's take 12.\n",
    "\n",
    "Later on we will be able to refine this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_all_centroid 0.028010052999889012\n",
      "order_clusters waveforms_rms\n",
      "find_clusters 0.3653124420015956\n",
      "CatalogueConstructor\n",
      "  chan_grp 0 - ch0 ch1 ch2 ch3\n",
      "  nb_peak_by_segment: 646, 677\n",
      "  some_waveforms.shape: (1323, 24, 4)\n",
      "  some_features.shape: (1323, 5)\n",
      "  cluster_labels [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "catalogueconstructor.find_clusters(method='kmeans', n_clusters=12)\n",
    "t2 = time.perf_counter()\n",
    "print('find_clusters', t2-t1)\n",
    "print(catalogueconstructor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open CatalogueWindow for visual check\n",
    "\n",
    "This open a CatalogueWindow, here we can check, split merge, trash, play as long as we are not happy.\n",
    "\n",
    "We happy, we can save the catalogue.\n",
    "\n",
    "Don't save nothing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_catalogue 0.02911864300040179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt5\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = tdc.CatalogueWindow(catalogueconstructor)\n",
    "win.show()\n",
    "app.exec_()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a snappshot of CatalogueWindow\n",
    "\n",
    "<img src=\"../doc/img/snapshot_cataloguewindow.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirty clean of catatalogue\n",
    "\n",
    "Here a quick and dirty clean of teh catalogue and them save it!!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_clusters waveforms_rms\n",
      "make_catalogue 0.02769362500112038\n"
     ]
    }
   ],
   "source": [
    "#order cluster by waveforms rms\n",
    "catalogueconstructor.order_clusters(by='waveforms_rms')\n",
    "\n",
    "#put label 0 to trash\n",
    "mask = catalogueconstructor.all_peaks['cluster_label'] == 0\n",
    "catalogueconstructor.all_peaks['cluster_label'][mask] = -1\n",
    "catalogueconstructor.on_new_cluster()\n",
    "\n",
    "#save the catalogue\n",
    "catalogueconstructor.make_catalogue_for_peeler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peeler\n",
    "\n",
    "Create and run the Peeler.\n",
    "It should be pretty fast, here the computation take 1.32s for 28.8x2s of signal. This is a speed up of 43 over real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 421/421 [00:00<00:00, 525.91it/s]\n",
      "100%|██████████| 421/421 [00:00<00:00, 517.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peeler.run 1.7563410889997613\n",
      "\n",
      "seg_num 0 nb_spikes 611\n",
      "seg_num 1 nb_spikes 648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "initial_catalogue = dataio.load_catalogue(chan_grp=0)\n",
    "\n",
    "peeler = Peeler(dataio)\n",
    "peeler.change_params(catalogue=initial_catalogue)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "peeler.run()\n",
    "t2 = time.perf_counter()\n",
    "print('peeler.run', t2-t1)\n",
    "\n",
    "print()\n",
    "for seg_num in range(dataio.nb_segment):\n",
    "    spikes = dataio.get_spikes(seg_num)\n",
    "    print('seg_num', seg_num, 'nb_spikes', spikes.size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open PeelerWindow for visual checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%gui qt5\n",
    "import pyqtgraph as pg\n",
    "app = pg.mkQApp()\n",
    "win = tdc.PeelerWindow(dataio=dataio, catalogue=initial_catalogue)\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a snappshot of PeelerWindow\n",
    "\n",
    "<img src=\"../doc/img/snapshot_peelerwindow.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
